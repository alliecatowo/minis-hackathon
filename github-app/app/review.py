"""Review generation: fetch mini personality, send diff to LLM, return review text."""

from __future__ import annotations

import logging

import httpx
import litellm

from app.config import settings

logger = logging.getLogger(__name__)

# Suppress litellm's verbose logging
litellm.suppress_debug_info = True

REVIEW_PROMPT = """You are reviewing a pull request. Here are the details:

## PR: {pr_title}

{pr_body}

## Diff

```diff
{diff}
```

---

Review this pull request. Focus on:
- Code correctness and potential bugs
- Design and architecture concerns
- Readability and maintainability
- Any security issues

Be specific — reference file names and line numbers from the diff when commenting.
Keep your review concise and actionable. If the PR looks good, say so briefly.

IMPORTANT: Stay completely in character. Your review should sound exactly like you would
write it — your tone, your priorities, your style of feedback. Don't be a generic code
reviewer. Be YOU reviewing this code."""


MENTION_PROMPT = """Someone mentioned you in a pull request conversation and asked:

"{user_message}"

## PR: {pr_title}

{pr_body}

## Diff

```diff
{diff}
```

---

Respond to their message. If they asked for a review, review the PR. If they asked a
specific question, answer it. Stay completely in character.

IMPORTANT: Your response should sound exactly like you would write it — your tone,
your priorities, your style. Be YOU."""


async def get_mini(username: str) -> dict | None:
    """Fetch a mini from the Minis backend API. Returns None if not found or not ready."""
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(
                f"{settings.minis_api_url}/api/minis/{username}",
                timeout=10.0,
            )
            if resp.status_code == 404:
                return None
            resp.raise_for_status()
            data = resp.json()
            if data.get("status") != "ready":
                return None
            return data
    except httpx.HTTPError as e:
        logger.error("Failed to fetch mini for %s: %s", username, e)
        return None


async def generate_review(
    mini: dict,
    pr_title: str,
    pr_body: str,
    diff: str,
) -> str:
    """Generate a PR review using the mini's personality."""
    system_prompt = mini["system_prompt"]

    # Augment the system prompt for code review context
    review_system = (
        f"{system_prompt}\n\n"
        "---\n\n"
        "You are now reviewing a pull request on GitHub. Stay in character. "
        "Review the code the way this developer actually would — with their values, "
        "their priorities, and their communication style. Format your review as markdown."
    )

    # Truncate diff if too large (keep first ~8000 chars)
    if len(diff) > 8000:
        diff = diff[:8000] + "\n\n... (diff truncated)"

    user_prompt = REVIEW_PROMPT.format(
        pr_title=pr_title,
        pr_body=pr_body or "_No description provided._",
        diff=diff,
    )

    messages = [
        {"role": "system", "content": review_system},
        {"role": "user", "content": user_prompt},
    ]

    response = await litellm.acompletion(
        model=settings.default_llm_model,
        messages=messages,
    )
    return response.choices[0].message.content


async def generate_mention_response(
    mini: dict,
    user_message: str,
    pr_title: str,
    pr_body: str,
    diff: str,
) -> str:
    """Generate a response to an @mention in a PR conversation."""
    system_prompt = mini["system_prompt"]

    review_system = (
        f"{system_prompt}\n\n"
        "---\n\n"
        "You are responding to a mention in a GitHub pull request conversation. "
        "Stay in character. Respond the way this developer actually would. "
        "Format your response as markdown."
    )

    if len(diff) > 8000:
        diff = diff[:8000] + "\n\n... (diff truncated)"

    user_prompt = MENTION_PROMPT.format(
        user_message=user_message,
        pr_title=pr_title,
        pr_body=pr_body or "_No description provided._",
        diff=diff,
    )

    messages = [
        {"role": "system", "content": review_system},
        {"role": "user", "content": user_prompt},
    ]

    response = await litellm.acompletion(
        model=settings.default_llm_model,
        messages=messages,
    )
    return response.choices[0].message.content


def format_review_comment(username: str, review_text: str) -> str:
    """Format a review with the mini's identity header."""
    return (
        f"### Review by @{username}'s mini\n\n"
        f"{review_text}\n\n"
        f"---\n"
        f"*This review was generated by [{username}'s mini](https://github.com/{username}) "
        f"— an AI personality clone powered by [Minis](https://github.com/alliecatowo/minis-hackathon).*"
    )
